{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1b4160-9d33-41c7-855f-d46f22f9ce0d",
   "metadata": {},
   "source": [
    "<img src=\"../../../images/banners/sklearn.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf33522-1d35-42fc-bc06-8e454060ab2a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"intro_to_data_structures\"></a>\n",
    "# <img src=\"../../../images/logos/sklearn.png\" width=\"40\"/> Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6ff76-a95a-4cda-9780-e4f537222b73",
   "metadata": {},
   "source": [
    "## <img src=\"../../../images/logos/toc.png\" width=\"20\"/> Table of Contents \n",
    "* [Getting Started](#getting_started)\n",
    "    * [Fitting and predicting: estimator basics](#fitting_and_predicting:_estimator_basics)\n",
    "    * [Transformers and pre-processors](#transformers_and_pre-processors)\n",
    "    * [Pipelines: chaining pre-processors and estimators](#pipelines:_chaining_pre-processors_and_estimators)\n",
    "    * [Model evaluation](#model_evaluation)\n",
    "    * [Automatic parameter searches](#automatic_parameter_searches)\n",
    "    * [Next steps](#next_steps)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95634962-a994-4d14-96c5-e1a12524742f",
   "metadata": {},
   "source": [
    "The purpose of this guide is to illustrate some of the main features that\n",
    "`scikit-learn` provides. It assumes a very basic working knowledge of\n",
    "machine learning practices (model fitting, predicting, cross-validation,\n",
    "etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ab2d8-be7c-4c13-9c34-dad51b25a662",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fitting_and_predicting:_estimator_basics\"></a>\n",
    "## Fitting and predicting: estimator basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b2e18-1085-40d1-9d51-03829a2d729e",
   "metadata": {},
   "source": [
    "`Scikit-learn` provides dozens of built-in machine learning algorithms and\n",
    "models, called [estimators](https://scikit-learn.org/stable/glossary.html#term-estimators). Each estimator can be fitted to some data\n",
    "using its [fit](https://scikit-learn.org/stable/glossary.html#term-fit) method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41ae97-4b1d-448a-90ca-d62ad0f85077",
   "metadata": {},
   "source": [
    "Here is a simple example where we fit a\n",
    "[`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier \"sklearn.ensemble.RandomForestClassifier\") to some very basic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b513f636-26e0-4bc3-ab4a-d9787e4e4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4084e5d3-1e41-4d42-92b9-9a622cf5f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766495dc-da6f-40b2-ab02-71cc85442da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[ 1,  2,  3],  # 2 samples, 3 features\n",
    "     [11, 12, 13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e6bb41-8d6b-496d-b93f-87584e51853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0, 1]  # classes of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc71fca8-3bcd-4375-97c2-c84f94ed5a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132020de-cb6b-419f-8eda-87801adc98db",
   "metadata": {},
   "source": [
    "The [fit](https://scikit-learn.org/stable/glossary.html#term-fit) method generally accepts 2 inputs:\n",
    "\n",
    "- The samples matrix (or design matrix) [X](https://scikit-learn.org/stable/glossary.html#term-X). The size of `X` is typically (`n_samples, n_features`), which means that samples are represented as rows and features are represented as columns.\n",
    "\n",
    "- The target values [y](https://scikit-learn.org/stable/glossary.html#term-y) which are real numbers for regression tasks, or integers for classification (or any other discrete set of values). For unsupervized learning tasks, `y` does not need to be specified. `y` is usually 1d array where the `i` th entry corresponds to the target of the `i` th sample (row) of `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac47f2-980c-4d2f-899e-2e3973fc2502",
   "metadata": {},
   "source": [
    "Both `X` and `y` are usually expected to be numpy arrays or equivalent\n",
    "[array-like](https://scikit-learn.org/stable/glossary.html#term-array-like) data types, though some estimators work with other\n",
    "formats such as sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3b1aa-297f-48b4-acc4-ea4f2701f2d4",
   "metadata": {},
   "source": [
    "Once the estimator is fitted, it can be used for predicting target values of\n",
    "new data. You don’t need to re-train the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f3763b-72d8-4dbd-ad9f-01ac11869a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)  # predict classes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a87d46dd-e5e9-409a-a3c5-1eb486fb5449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4, 5, 6], [14, 15, 16]])  # predict classes of new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743d03d-50c2-43f7-a644-bebc72528c97",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"transformers_and_pre-processors\"></a>\n",
    "## Transformers and pre-processors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e021f8-442d-4bf0-a9c7-5acf0749737a",
   "metadata": {},
   "source": [
    "Machine learning workflows are often composed of different parts. A typical\n",
    "pipeline consists of a pre-processing step that transforms or imputes the\n",
    "data, and a final predictor that predicts target values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc2e07-10cb-4fe9-80bb-d59e00a4eff5",
   "metadata": {},
   "source": [
    "In `scikit-learn`, pre-processors and transformers follow the same API as\n",
    "the estimator objects (they actually all inherit from the same\n",
    "`BaseEstimator` class). The transformer objects don’t have a\n",
    "[predict](https://scikit-learn.org/stable/glossary.html#term-predict) method but rather a [transform](https://scikit-learn.org/stable/glossary.html#term-transform) method that outputs a\n",
    "newly transformed sample matrix `X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba728084-adcc-4ce6-be16-ba7799ef4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceb265ce-b665-4383-a73b-46f058b58112",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0, 15],\n",
    "     [1, -10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861fce1a-e995-497d-8ddc-f1bb6d9f524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.],\n",
       "       [ 1., -1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale data according to computed scaling values\n",
    "StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae1c3e-6264-4bd2-8d5a-a5156230d17b",
   "metadata": {},
   "source": [
    "Sometimes, you want to apply different transformations to different features:\n",
    "the [ColumnTransformer](https://scikit-learn.org/stable/modules/compose.html#column-transformer) is designed for these\n",
    "use-cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d41490c-ab54-4383-8b0d-a79590873b05",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pipelines:_chaining_pre-processors_and_estimators\"></a>\n",
    "## Pipelines: chaining pre-processors and estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a5e06-cfa6-4060-b50d-550fbedde6b9",
   "metadata": {},
   "source": [
    "Transformers and estimators (predictors) can be combined together into a\n",
    "single unifying object: a [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline \"sklearn.pipeline.Pipeline\"). The pipeline\n",
    "offers the same API as a regular estimator: it can be fitted and used for\n",
    "prediction with `fit` and `predict`. As we will see later, using a\n",
    "pipeline will also prevent you from data leakage, i.e. disclosing some\n",
    "testing data in your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2c32a-0554-49ac-8439-c1e0d4f7bc2b",
   "metadata": {},
   "source": [
    "In the following example, we [load the Iris dataset](https://scikit-learn.org/stable/datasets.html#datasets), split it\n",
    "into train and test sets, and compute the accuracy score of a pipeline on\n",
    "the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2828d0df-b0b2-4a5e-a386-843534eed5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40116499-ae17-443b-bdd7-047c17e12382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline object\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c4bc07-5d65-4c26-b610-9a088641c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the iris dataset and split it into train and test sets\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e75c55fb-7d3b-4693-a0db-b15421a8a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9df108b3-dfa0-4e63-b539-bd413858e721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f27ae4-856e-4db2-93c7-f39802cf38e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now use it like any other estimator\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248f3ec-a866-407a-9241-d1c7875d7f8f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"model_evaluation\"></a>\n",
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e49d1-cc07-4810-a62b-daa435f50266",
   "metadata": {},
   "source": [
    "Fitting a model to some data does not entail that it will predict well on\n",
    "unseen data. This needs to be directly evaluated. We have just seen the\n",
    "[`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split \"sklearn.model_selection.train_test_split\") helper that splits a\n",
    "dataset into train and test sets, but `scikit-learn` provides many other\n",
    "tools for model evaluation, in particular for [cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da476e75-93dc-4156-b787-cb7d40245440",
   "metadata": {},
   "source": [
    "We here briefly show how to perform a 5-fold cross-validation procedure,\n",
    "using the [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate \"sklearn.model_selection.cross_validate\") helper. Note that\n",
    "it is also possible to manually iterate over the folds, use different\n",
    "data splitting strategies, and use custom scoring functions. Please refer to\n",
    "our [User Guide](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) for more details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ded9f60c-e877-42c0-ad6d-a9a50cb06944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57bd7817-1278-42b3-8cdc-0ce6725b87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e550df0f-1a44-4ff2-889b-2724dda5af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48c12384-6062-4b5a-bf55-ecacd1d61a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cross_validate(lr, X, y)  # defaults to 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8afe9152-90e4-4d75-9268-a38470f64d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['test_score']  # r_squared score is high because dataset is easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae1d2a-9b9a-4a25-84d0-3329cbf39018",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"automatic_parameter_searches\"></a>\n",
    "## Automatic parameter searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f32bc-2ba6-46a7-9d92-1114d13f6b14",
   "metadata": {},
   "source": [
    "All estimators have parameters (often called hyper-parameters in the\n",
    "literature) that can be tuned. The generalization power of an estimator\n",
    "often critically depends on a few parameters. For example a\n",
    "[`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor \"sklearn.ensemble.RandomForestRegressor\") has a `n_estimators`\n",
    "parameter that determines the number of trees in the forest, and a\n",
    "`max_depth` parameter that determines the maximum depth of each tree.\n",
    "Quite often, it is not clear what the exact values of these parameters\n",
    "should be since they depend on the data at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e60d27-3a9e-42c8-8a22-c02dc99b5f9c",
   "metadata": {},
   "source": [
    "`Scikit-learn` provides tools to automatically find the best parameter\n",
    "combinations (via cross-validation). In the following example, we randomly\n",
    "search over the parameter space of a random forest with a\n",
    "[`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV \"sklearn.model_selection.RandomizedSearchCV\") object. When the search\n",
    "is over, the [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV \"sklearn.model_selection.RandomizedSearchCV\") behaves as\n",
    "a [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor \"sklearn.ensemble.RandomForestRegressor\") that has been fitted with\n",
    "the best set of parameters. Read more in the [User Guide](https://scikit-learn.org/stable/modules/grid_search.html#grid-search):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b3bb74d-ef06-477a-a93b-dfff17c83d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b60e44a-e01e-4b8d-8983-71b3fb5d06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a37ff015-5ca6-4f14-ba95-22c0efdf153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5246f65-7fa0-468f-bf7d-a1fa3bc447b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter space that will be searched over\n",
    "param_distributions = {'n_estimators': randint(1, 5), 'max_depth': randint(5, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d82abbbe-718f-4f72-b26c-2205946aeb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=0),\n",
    "    n_iter=5,\n",
    "    param_distributions=param_distributions,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de1d626c-e0f7-46ef-9530-b7336a7aab19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0), n_iter=5,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f8310222cd0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f83500f2be0>},\n",
       "                   random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81ec2baa-9d96-4ac7-8b72-56fcf2f870f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bf15c96-a998-4ef2-9cd2-9a14122a2d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735363411343253"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the search object now acts like a normal random forest estimator\n",
    "# with max_depth=9 and n_estimators=4\n",
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64525c-23fa-41ed-ac33-0aad54fda97d",
   "metadata": {},
   "source": [
    "> **Note:**\n",
    "In practice, you almost always want to [search over a pipeline](https://scikit-learn.org/stable/modules/grid_search.html#composite-grid-search), instead of a single estimator. One of the main\n",
    "reasons is that if you apply a pre-processing step to the whole dataset\n",
    "without using a pipeline, and then perform any kind of cross-validation,\n",
    "you would be breaking the fundamental assumption of independence between\n",
    "training and testing data. Indeed, since you pre-processed the data\n",
    "using the whole dataset, some information about the test sets are\n",
    "available to the train sets. This will lead to over-estimating the\n",
    "generalization power of the estimator (you can read more in this [Kaggle\n",
    "post](https://www.kaggle.com/alexisbcook/data-leakage))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1673653-bc6a-4bc2-a8d0-dc92fbafcb38",
   "metadata": {},
   "source": [
    "Using a pipeline for cross-validation and searching will largely keep\n",
    "you from this common pitfall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77a0fd-697d-43a1-a4c5-e3dfbfed8569",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"next_steps\"></a>\n",
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1676bdc-d1e9-4c1b-9327-1abab3962852",
   "metadata": {},
   "source": [
    "We have briefly covered estimator fitting and predicting, pre-processing\n",
    "steps, pipelines, cross-validation tools and automatic hyper-parameter\n",
    "searches. This guide should give you an overview of some of the main\n",
    "features of the library, but there is much more to `scikit-learn`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0adf45b-ad63-44ec-bc65-a1572e745154",
   "metadata": {},
   "source": [
    "Please refer to [User Guide](https://scikit-learn.org/stable/user_guide.html#user-guide) for details on all the tools that we\n",
    "provide. You can also find an exhaustive list of the public API in the\n",
    "[API Reference](https://scikit-learn.org/stable/modules/classes.html#api-ref)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47132fc2-d86a-49bb-af60-e5614ef58eba",
   "metadata": {},
   "source": [
    "You can also look at our numerous [examples](https://scikit-learn.org/stable/auto_examples/index.html#general-examples) that\n",
    "illustrate the use of `scikit-learn` in many different contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6095ec-4737-4f76-abef-c8ba857b17bf",
   "metadata": {},
   "source": [
    "The [tutorials](https://scikit-learn.org/stable/tutorial/index.html#tutorial-menu) also contain additional learning\n",
    "resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
