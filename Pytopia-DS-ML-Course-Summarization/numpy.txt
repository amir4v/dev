np.array([...])

np.arange(n)

np.random.rand(d1, d2, d3, ..., dn)

np.random.random( (d1, d2, d3, ..., dn) )

np.random.randint( low, high, size )

np.zeros( (d1, d2, d3, ..., dn) )
np.ones( (d1, d2, d3, ..., dn) )
np.eye(n)
np.eye(d1, d2, d3, ..., dn)

np.clip( ndarray , min-ndarray, max-val )

np.vectorize( func )
    it returns a function than can be applied on ndarrays without for loop.

np.asfortranarray( an-array )

%timeit ...

view
np.may_share_memory(arr1, arr2)

np.empty( (d1, d2, d3, ..., dn) )

strides
    indicates the number of bytes to jump to the next element.

.flatten()
    returns items in a row.

np.swapaxes( ndarray, axis-m, axis-n )
    like a rotation.

-1 in reshaping means the remaining shape size of the transferred array.

The difference between .flatten() and .ravel() is the flatten function creates a copy from the original array.

Broadcasting is subject to certain constraints: the smaller array is "broadcast" across the larger array so that they have compatible shapes.

[1,2,3,4] * 2 = [1,2,3,4] * [2,2,2,2]

axis-0 is column in numpy
axis-1 is row in numpy

All arrays generated by basic slicing are always views of the original array.
basic slicing: i:j:k

np.random.randint(n) -> scalar
np.random.randint(n, size=(d1, d2, d3, ..., dn))
np.random.randint( low, high, size=(d1, d2, d3, ..., d) )

slice object

Ellipsis == ... == a[...] == a == a[Ellipsis]
a[..., 3]
a[3, ...]
a[0, ..., 5]

new axis = np.newaxis == None
a[None, ..., np.newaxis]

Advanced indexing returns a copy of the data.
There are two type of advanced indexing: integer and boolean.

a[ [1,2,3,4] ]
a[ ndarray ]
a[ (1,2,3,4), ]
a[1,2,3,4] == a[(1,2,3,4)]
a[ rows , columns ]
a[ [True, False] , : ]

np.nan

a[~a.isnan()]
~a.isnan().nonzero()
a[a > 0]
a[a > 0] + 20

np.linspace( from , to , in-how-many-pieces )
np.linspace( from , to , in-how-many-pieces , dtype=np.int8 )

.reshape(4, -1) , -1 is equivalent to saying that calculate the amount of this dimension by yourself.

np.random.default_rng().standard_normal( n )
    Getting a range of random numbers with a normal distribution.

.std() = Standard deviation

mask = a[ condition1 & condition2  | condition3 ]

.T or .transpose()
    Transposing

np.sort( a ) == np.sort(axis=1)
np.sort(a, axis=None)
    Means do it linear.

axis=0 == column
axis=1 == row
a[ row-axis , column-axis ]

Concatenate
    np.hstack( (a , b) )
    np.vstack( (a , b) )
    np.concatenate( (a,b) ) == np.concatenate( (a,b), axis=0 )
    np.concatenate((a,a), axis=None)
        Concatenate them linearly

.max/.min/.mean/.std/.sum() or (axis=None/0/1 which default is None)

dt = np.dtype('>i4')
    a big endian 4 byte integer
dt.name == int32
dt.type == np.int32
dt.byteorder == '>'
dt.itemsize == 4

dt = np.dtype([('name', np.unicode_, 16), ('grade', np.float64, (2,))]) == dtype([('name', '<U16'), ('grade', '<f8', (2,))])
x = np.array([('Sarah', (4, 5)), ('Amir', (3,7))], dtype=dt)
x[0]['grade']
type(x[0]) == np.void
type(x[0]['grade']) np.ndarray

np.dtype(int) == np.int32

np.single == np.float32
np.unit8
np.array(['first', 'amir', 'abcdef'])
    it takes a '<U6' dtype because of the biggest string length.

Note: When dealing with NumPy data types, you have to think about things like
the endianness of your values. In this case, the dtype '<U3' means that each
value is the size of three Unicode characters, with the least-significant byte
stored first in memory and the most-significant byte stored last. A dtype of '>U3' would signify the reverse.

.tobytes()

If try to modify a value of <Un dtype which the value is larger than the capacity
of the dtype then the value will get cut.

np.empty( (d1, ...) , dtype=... )
np.empty( (d1, ...) , dtype=('i8, f4, U10') )
x['f0'] means Field-Zero
    shows all data with the dtype of 'f4' because this dtype still has its default name which can be changed.

bn in fn un cn an
bytes, integer, float, unsigned-integer, complex, fixed-length-string
like: b1, i4, f2, u4, c8, a9
and you can specify the dimension of the dtype before that like:
3i4 -> [1,4,8]
(2,3)f4 -> [ [3,6,8] , [3,6,8] ]

x.dtype.names
    f0, f1, f2, ... (by default of course)

dtype (list of):
dtype=[ (name, type, size) , ('id', 'i8', (2,3)) ]
dtype={'names':['id', 'grade'], 'formats':['i4', 'f4']}

x[ ['f0', 'f1'] ]

x[ x['age'] > 44 ]['name']
np.sort( x[ x['age'] > 44 ]['name'] )

np.datetime64
dt = np.datetime64('2012-01-01')
dt.dtype = '<M8[D]'
np.arange('2012-01-01', '2020-01-01', dtype='<M8[M]')
dt = np.arange('2012-01-01', '2020-01-01', dtype='datetime64[M]')
dt.tolist()
    gives pythonic datetime objects.
dt[0].item()
    gives the pythonic datetime object.
[i.item() for i in dt] == dt.tolist()
np.timedelta64
np.timedelta64(13, 'D')
np.timedelta64(13, 'M')
np.timedelta64(13, 'W')
np.array([datetime.datetime(2012, 12, 12)], dtype=np.datetime64)
    converting pythonic datetime to numpy datetime64.

csv = Comma Separated Values
HDF5 = Hierarchical Data Format
HDFStore class in pandas

np.random.randint(low, high, how-many)

_id = np.arange(1000)
_value = np.random.random(1000)
_date = np.random.randint(0, 365, 1000) + np.datetime64('2020-01-01')
np.core.records.fromarrays(
    [_id, _value, _date],
    names='id, value, date',
    formats='i4, f4, a10'
)
    Output:
    rec.array([
        (  0, 3.36312473e-01, b'2020-01-01'),
        (  2, 4.19886410e-02, b'2020-02-09'),
        (  3, 2.43261382e-01, b'2020-09-24'),
        ...
        (997, 7.31472492e-01, b'2020-10-04'),
        (998, 4.00770158e-01, b'2020-01-08'),
        (999, 3.29402268e-01, b'2020-01-22')],
        dtype=[('id', '<i4'), ('value', '<f4'), ('date', 'S10')])
np.core.records.fromarrays
    Does not support np.datetime64 dtype.

b here stands for "bytes literals" meaning it only contains ASCII characters
(all string types in Python 3 are Unicode, which is one major change between Python 2 and 3).

np.savetxt('./records.csv', x, fmt='%i, %.4f, %s')

x = np.genfromtxt(
    './records.csv',
    dtype='i4, f4, a10',
    delimiter=',',
    skip_header=0
)
x.dtype.names = 'id', 'value', 'date'
    You may notice we lost the fields names, so let's specify them.
np.genfromtext

NumPy binary files
    .npy and .npz
The `load`(), `save`(), `savez`(), and `savez_compressed`() methods help you to load and save NumPy binary files.

np.save('x.npy', x, allow_pickle=False)
x = np.load('./x.npy')

Note: Set allow_pickle=False in numpy.save and numpy.load unless the array dtype includes Python objects, in which case pickling is required.
Pickles are not secure against erroneous or maliciously constructed data.

np.savez
    to save several arrays
    np.savez('x_a.npz', x, a)
    x_a = np.load('./x_a.npz')
    x_a.files
        ['arr_0', 'arr_1']
    x_a['arr_0']
    np.savez('x_a.npz', x=x, a=a)
    np.savez_compressed
        exactly like savez but compressed

Note: In general, prefer numpy.save and numpy.load to numpy.ndarray.tofile and
numpy.fromfile as they lose information on endianness and precision and so are unsuitable for anything but scratch storage.

Warning: numpy arrays are not directly json serializable.

Linear Algebra

matrix object
polynomial object

The matrix object in numpy inherits all the attributes and methods from ndarray, but it's strictly two-dimensional.
the * notion for two matrices is their matrix product like @ in ndarryas.

np.matrix(ndarray)
    makes a copy from it
np.mat(ndarray)
    changes the view only
np.matrix(ndarray, copy=False) exactly-equal-to np.mat(ndarray)

np.identity(3)
    [[1., 0., 0.],
    [0., 1., 0.],
    [0., 0., 1.]]

np.matrix('1 2 3; 4 5 6; 7 8 9')
x = np.matrix([[1,2,3],[4,5,6],[7,8,9]])
np.dot(ndar1, ndar2, ...) is matrix product
x.I
    Inverse
x.T
    Transpose
x.H
    Hermitian

np.allclose

m.A
    returns the basic ndarray of a matrix.
m.A1
    returns a one dimensional ndarray.

x = np.array([
    [1, 2],
    [3, 4]
])
y = np.array([
    [10, 20],
    [30, 40]
])
np.dot(x, y)
    (1*10+2*30) (1*30+2*40)
    (3*10+4*30) (3*30+4*40)
    =
    70  100
    150 220

np.vdot
    handles multi-dimensional arrays differently than np.dot, it does not perform a
    matrix product, but flattens input arguments to one dimensional vectors first.
np.dot(x, y)
    1*10 + 2*20 + 3*30 + 4*40 = 300

np.outer
    is the outer product of two vectors.
آرایه اول رو خطی به صورت ستونی-طور میچینه و به تعداد اعضای آرای دوم این ستون رو
تکرار میکنه و هر ستون رو در هر عضو آرایه دوم ضرب میکنه

np.cross
    a binary operation(product) of two vectors

np.linalg

np.linalg.det(ndarray)
    determinant

np.linalg.inv(ndarray) == numpy.matrix-object.I

np.linalg.solv( coefficient , dependent-variable )

np.linalg.eig(ndarray)
    Eigenvalues and Eigenvectors

np.linalg.svd(ndarray)
    Singular value decomposition

np.diag(ndarray)
    diagonal
    [1,2,3]
        [
            [1,0,0],
            [0,2,0],
            [0,0,3]
        ]
    [[1,2],[3,4]]
        [1,4]

np.linalg.qr
    QR decomposition / Polar decomposition

np.polynomial
np.poly(roots)
    takes roots and returns coefficients.
np.roots(coefficients)
    takes coefficients and returns roots.
np.polyval(coefficients, val)
    takes coefficients and a val=x and calculates the equation in that point.
np.polyint(coefficients)
    takes coefficients of an equation and calculates integral of it.
np.polyder(ndarray)
    calculates the derevation.
np.polyder(np.polyint(np.array([1,2,3,4]))) == np.array([1,2,3,4])
